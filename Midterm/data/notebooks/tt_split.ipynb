{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt=pd.read_csv(\"gpt4o.csv\") #beauty\n",
    "mixtral=pd.read_csv(\"mixtral.csv\") #bad class\n",
    "llama=pd.read_csv(\"llama3.csv\") # competing beauty\n",
    "gemma=pd.read_csv(\"gemma.csv\") # eww\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1221 entries, 0 to 1220\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   xi      1221 non-null   object\n",
      " 1   xj      1221 non-null   object\n",
      " 2   LLM     1221 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 28.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(gpt.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1221 entries, 0 to 1220\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   xi      1221 non-null   object\n",
      " 1   xj      1221 non-null   object\n",
      " 2   LLM     1221 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 28.7+ KB\n"
     ]
    }
   ],
   "source": [
    "llama.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1221 entries, 0 to 1220\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   xi      1221 non-null   object\n",
      " 1   xj      1221 non-null   object\n",
      " 2   LLM     1221 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 28.7+ KB\n"
     ]
    }
   ],
   "source": [
    "mixtral.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1221 entries, 0 to 1220\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   xi      1221 non-null   object\n",
      " 1   xj      1221 non-null   object\n",
      " 2   LLM     1221 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 28.7+ KB\n"
     ]
    }
   ],
   "source": [
    "gemma.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 3844\n",
      "Eval dataset size: 480\n",
      "Test dataset size: 560\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df1, df2, df3, and df4 are your dataframes for each class\n",
    "dataframes = [gpt, llama, mixtral, gemma]\n",
    "\n",
    "train_frames = []\n",
    "eval_frames = []\n",
    "test_frames = []\n",
    "\n",
    "for df in dataframes:\n",
    "    # Select the first 800 samples for training\n",
    "    train_df = df.iloc[:800]\n",
    "    \n",
    "    # Select the samples from 1000 to 1160 for training\n",
    "    train_df_extra = df.iloc[1000:1161]\n",
    "    \n",
    "    # Combine the two parts of training data\n",
    "    train_frames.append(pd.concat([train_df, train_df_extra]))\n",
    "    \n",
    "    # Use the rest for eval and test (remaining samples from 800 to 999, and 1161 onwards)\n",
    "    eval_df = df.iloc[800:900]  # 100 samples for eval\n",
    "    eval_df_extra = df.iloc[1161:1181] #20\n",
    "    test_df = df.iloc[900:1000]  # 100 samples for test\n",
    "    test_df_extra = df.iloc[1181:1222] #20\n",
    "\n",
    "    eval_frames.append(pd.concat([eval_df, eval_df_extra]))\n",
    "\n",
    "    test_frames.append(pd.concat([test_df, test_df_extra]))\n",
    "\n",
    "# Combine the dataframes for train, eval, and test sets\n",
    "train_dataset = pd.concat(train_frames)\n",
    "eval_dataset = pd.concat(eval_frames)\n",
    "test_dataset = pd.concat(test_frames)\n",
    "\n",
    "# Shuffle the datasets to ensure uniformity and avoid bias\n",
    "train_dataset = train_dataset.sample(frac=1).reset_index(drop=True)\n",
    "eval_dataset = eval_dataset.sample(frac=1).reset_index(drop=True)\n",
    "test_dataset = test_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Check the sizes of the datasets\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Eval dataset size: {len(eval_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3844 entries, 0 to 3843\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   xi      3844 non-null   object\n",
      " 1   xj      3844 non-null   object\n",
      " 2   LLM     3844 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 90.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=\"train.csv\"\n",
    "eval_set=\"eval.csv\"\n",
    "test_set=\"test.csv\"\n",
    "\n",
    "train_dataset.to_csv(train_set, index=False)\n",
    "eval_dataset.to_csv(eval_set, index=False)\n",
    "test_dataset.to_csv(test_set, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
